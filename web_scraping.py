# -*- coding: utf-8 -*-
"""Web Scraping

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YG_ZWjehGqg8JeI29qM16292Ou7SMae7
"""

# import BeautifulSoup for web scrapping
# import requests for request HTTP data with all response data
# import pandas for data manipulation and analysis
from bs4 import BeautifulSoup
import requests
import pandas as pd

url = 'https://en.m.wikipedia.org/wiki/List_of_largest_companies_in_Indonesia'
page = requests.get(url)
soup = BeautifulSoup(page.text, 'html')

print(soup)

# find_all to find every table in page
soup.find_all('table')

# define table and use [1] because the table we want in position 1
table = soup.find_all('table')[1]

print(table)

# 'th' is the header we want
b1 = table.find_all('th')
b1

# take out header and clean the string
header = [title.text.strip() for title in b1]
print(header)

# build dataframe
df = pd.DataFrame(columns = header)
df

# content of the table per row is located in 'tr'
column_data = table.find_all('tr')
column_data

# take the content per row by 'td'
for row in column_data:
    row_data = row.find_all('td')
    individual_row_data = [data.text.strip() for data in row_data]
    print(individual_row_data)

# clear the empty row using [1:]
for row in column_data[1:]:
  row_data = row.find_all('td')
  individual_row_data = [data.text.strip() for data in row_data]
# insert the table content to dataframe
  length = len(df)
  df.loc[length] = individual_row_data

df

# to save dataframe
from google.colab import files

# download as csv
df.to_csv('List largest company in Indonesia by Forbes 200.csv', encoding = 'utf-8-sig')
files.download('List largest company in Indonesia by Forbes 200.csv')

# save as csv to google drive
drive.mount('/content/drive')
path = '/content/drive/My Drive/List largest company in Indonesia by Forbes 200.csv'
with open(path, 'w', encoding = 'utf-8-sig') as f:
  df.to_csv(f)